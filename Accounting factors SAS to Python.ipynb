{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "#the first line is necessary to run this code on server\n",
    "\n",
    "##########################################\n",
    "# Accounting Factors translated from SAS \n",
    "# December 03 2019\n",
    "# Created by Xinyu LIU\n",
    "##########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import wrds\n",
    "import psycopg2 \n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *\n",
    "from pandas.core.frame import DataFrame\n",
    "from scipy import stats\n",
    "import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "###################\n",
    "# Connect to WRDS #\n",
    "###################\n",
    "conn = wrds.Connection(wrds_username='dachxiu')\n",
    "#make it a constant portal by creating ppass\n",
    "\n",
    "###################\n",
    "# Compustat Block #\n",
    "###################\n",
    "comp = conn.raw_sql(\"\"\"\n",
    "                    select \n",
    "                    f.cusip as cnum, c.gvkey, datadate, datadate as\n",
    "                    datadate_a, fyear, c.cik, sic as sic2, sic, naics, \n",
    "                    sale, revt, cogs, xsga, dp, xrd, xad, ib, ebitda, ebit, nopi, spi, pi, txp, \n",
    "                    ni, txfed, txfo, txt, xint, \n",
    "                    capx, oancf, dvt, ob, gdwlia, gdwlip, gwo, \n",
    "                    rect, act, che, ppegt, invt, at, aco, intan, ao, ppent, gdwl, fatb, fatl, \n",
    "                    lct, dlc, dltt, lt, dm, dcvt, cshrc, dcpstk, pstk, ap, lco, lo, drc, drlt, txdi,\n",
    "                    ceq, scstkc, emp, csho, /*addition*/\n",
    "                    pstkrv, pstkl, txditc, datadate as year, /*market*/\n",
    "                    abs(prcc_f) as prcc_f, csho*prcc_f as mve_f, /*HXZ*/\n",
    "                    am, ajex, txdb, seq, dvc, dvp, dp, dvpsx_f, mib, ivao, ivst, sstk, prstkc, \n",
    "                    dv, dltis, dltr, dlcch, oibdp, dvpa, tstkp, oiadp, xpp, xacc, re, ppenb, \n",
    "                    ppenls, capxv, fopt, wcap\n",
    "                    from comp.names as c, comp.funda as f\n",
    "                    where \n",
    "                    f.gvkey=c.gvkey\n",
    "                    /*get consolidated, standardized, industrial format statements*/\n",
    "                    and f.indfmt='INDL' \n",
    "                    and f.datafmt='STD'\n",
    "                    and f.popsrc='D'\n",
    "                    and f.consol='C'\n",
    "                    and datadate >= '01/01/2015'\n",
    "                    \"\"\")\n",
    "\n",
    "# Due to limited functionality caused by using sql on python, need to manually make up the modifiers work in SAS sql\n",
    "comp.cnum=comp.cnum.replace(' ','').str.slice(0, 6)\n",
    "comp.sic2=comp.sic2+'12'\n",
    "comp.datadate=pd.to_datetime(comp.datadate)\n",
    "comp.year = comp.datadate.dt.year\n",
    "comp=comp.dropna(subset=['at','prcc_f','ni'])\n",
    "\n",
    "# create preferrerd stock\n",
    "comp['ps']=np.where(comp['pstkrv'].isnull(), comp['pstkl'], comp['pstkrv'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),comp['pstk'], comp['ps'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),0,comp['ps'])\n",
    "#manipulate ps data in the sequense of redemption, liquidating and total value, last resolution is 0\n",
    "\n",
    "comp['txditc']=comp['txditc'].fillna(0)\n",
    "\n",
    "# create book equity\n",
    "comp['be']=comp['ceq']+comp['txditc']-comp['ps']\n",
    "comp['be']=np.where(comp['be']>0,comp['be'],None)\n",
    "#comp['be']=np.where(comp['be']>0, comp['be'], np.nan)\n",
    "#Book value of equity equals to Stockholders Equity + Deferred Tax - Preferred Stocks \n",
    "#set nan value for book equity that is less than 0\n",
    "\n",
    "# number of years in Compustat\n",
    "comp=comp.sort_values(by=['gvkey','datadate']).drop_duplicates()\n",
    "\n",
    "# number of years in Compustat\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "#Sort DataFrame by column gvkey and datadate\n",
    "#Mark cumulative number of each gvkey as of that row, starting from 0\n",
    "\n",
    "\n",
    "###################\n",
    "# CRSP Block      #\n",
    "###################\n",
    "# sql similar to crspmerge macro\n",
    "crsp_m = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.ticker, b.ncusip, b.shrcd, b.exchcd, b.siccd,\n",
    "                      a.prc, a.ret, a.retx, a.shrout, a.vol\n",
    "                      from crsp.msf as a\n",
    "                      left join crsp.msenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '07/01/2016' and '06/30/2018'\n",
    "                      and b.exchcd between 1 and 3\n",
    "                      and b.shrcd between 10 and 11\n",
    "                      \"\"\") \n",
    "#b.dlprc does not exist\n",
    "\n",
    "# change variable format to int\n",
    "crsp_m[['permco','permno','shrcd','exchcd']]=crsp_m[['permco','permno','shrcd','exchcd']].astype(int)\n",
    "\n",
    "# Line up date to be end of month\n",
    "crsp_m['date']=pd.to_datetime(crsp_m['date'])\n",
    "crsp_m['jdate']=crsp_m['date']+MonthEnd(0)\n",
    "#The 1 in MonthEnd just specifies to move one step forward to the next date that's a month end.\n",
    "\n",
    "# add delisting return\n",
    "dlret = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.msedelist\n",
    "                     \"\"\")\n",
    "#MSEDELIST\t\tCRSP Monthly Stock Event - Delisting\n",
    "#DLRET \tNum\t8\tDelisting Return,DLRET is the return of the security after it is delisted. \n",
    "#It is calculated by comparing a value after delisting against the price on the security's last trading date. \n",
    "#The value after delisting can include a delisting price or the amount from a final distribution.\n",
    "#DLSTDT \tNum\t8\tDelisting Date,DLSTDT contains the date (in YYMMDD format) of a security's last price on the current exchange.\n",
    "\n",
    "#process dlret\n",
    "dlret.permno=dlret.permno.astype(int)\n",
    "dlret['dlstdt']=pd.to_datetime(dlret['dlstdt'])\n",
    "dlret['jdate']=dlret['dlstdt']+MonthEnd(0)\n",
    "\n",
    "#merge dlret and crsp_m\n",
    "crsp = pd.merge(crsp_m, dlret, how='left',on=['permno','jdate'])\n",
    "#crsp and dlret share the same column names: permno and jdate\n",
    "\n",
    "#process crsp\n",
    "crsp['dlret']=crsp['dlret'].fillna(0)\n",
    "crsp['ret']=crsp['ret'].fillna(0)\n",
    "crsp['retadj']=(1+crsp['ret'])*(1+crsp['dlret'])-1\n",
    "\n",
    "# calculate market equity\n",
    "crsp['me']=crsp['prc'].abs()*crsp['shrout']\n",
    "# Newly added columns in parallel with SAS code, not necessary to be here \n",
    "# lag absolute close price, market cap\n",
    "crsp['prca']=crsp['prc'].abs()\n",
    "crsp['lprc']=crsp.groupby(['permno','permco'])['prca'].shift(1)\n",
    "crsp['lme']=crsp.groupby(['permno','permco'])['me'].shift(1)\n",
    "#market equity equals to price of stock times shares of outstanding\n",
    "\n",
    "#process crsp\n",
    "crsp=crsp.drop(['dlret','dlstdt'], axis=1)\n",
    "crsp=crsp.sort_values(by=['jdate','permco','me']).drop_duplicates()\n",
    "\n",
    "### Aggregate Market Cap ###\n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crsp_summe = crsp.groupby(['jdate','permco'])['me'].sum().reset_index()\n",
    "# largest mktcap within a permco/date\n",
    "crsp_maxme = crsp.groupby(['jdate','permco'])['me'].max().reset_index()\n",
    "# join by jdate/maxme to find the permno\n",
    "crsp1=pd.merge(crsp, crsp_maxme, how='inner', on=['jdate','permco','me'])\n",
    "# drop me column and replace with the sum me\n",
    "crsp1=crsp1.drop(['me'], axis=1)\n",
    "# join with sum of me to get the correct market cap info\n",
    "crsp2=pd.merge(crsp1, crsp_summe, how='inner', on=['jdate','permco'])\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2=crsp2.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "# important to have a duplicate check\n",
    "\n",
    "\n",
    "# keep December market cap\n",
    "crsp2['year']=crsp2['jdate'].dt.year\n",
    "crsp2['month']=crsp2['jdate'].dt.month\n",
    "decme=crsp2[crsp2['month']==12]\n",
    "decme=decme[['permno','date','jdate','me','year']].rename(columns={'me':'dec_me'})\n",
    "\n",
    "### July to June dates\n",
    "crsp2['ffdate']=crsp2['jdate']+MonthEnd(-6)\n",
    "crsp2['ffyear']=crsp2['ffdate'].dt.year\n",
    "crsp2['ffmonth']=crsp2['ffdate'].dt.month\n",
    "crsp2['1+retx']=1+crsp2['retx']\n",
    "crsp2=crsp2.sort_values(by=['permno','date'])\n",
    "\n",
    "# cumret by stock\n",
    "crsp2['cumretx']=crsp2.groupby(['permno','ffyear'])['1+retx'].cumprod()\n",
    "#cumprod returns the product of the year in this case, which is the cumulative return as time goes by\n",
    "\n",
    "# lag cumret\n",
    "crsp2['lcumretx']=crsp2.groupby(['permno'])['cumretx'].shift(1)\n",
    "\n",
    "# lag market cap\n",
    "crsp2['lme']=crsp2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crsp2['count']=crsp2.groupby(['permno']).cumcount()\n",
    "crsp2['lme']=np.where(crsp2['count']==0, crsp2['me']/crsp2['1+retx'], crsp2['lme'])\n",
    "\n",
    "# baseline me\n",
    "mebase=crsp2[crsp2['ffmonth']==1][['permno','ffyear', 'lme']].rename(columns={'lme':'mebase'})\n",
    "\n",
    "# merge result back together\n",
    "crsp3=pd.merge(crsp2, mebase, how='left', on=['permno','ffyear'])\n",
    "crsp3['wt']=np.where(crsp3['ffmonth']==1, crsp3['lme'], crsp3['mebase']*crsp3['lcumretx'])\n",
    "\n",
    "decme['year']=decme['year']+1\n",
    "decme=decme[['permno','year','dec_me']]\n",
    "\n",
    "# Info as of June\n",
    "crsp3_jun = crsp3[crsp3['month']==6]\n",
    "\n",
    "crsp_jun = pd.merge(crsp3_jun, decme, how='inner', on=['permno','year'])\n",
    "\n",
    "# Because I haven't reach the end of the code so will temporarily leave this subslicing open\n",
    "# crsp_jun=crsp_jun[['permno','date', 'jdate', 'shrcd','exchcd','retadj','me','wt','cumretx','mebase','lme','dec_me']]\n",
    "crsp_jun=crsp_jun.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "crsp_jun=crsp_jun.drop(columns=['count'])\n",
    "\n",
    "#######################\n",
    "# CCM Block           #\n",
    "#######################\n",
    "ccm=conn.raw_sql(\"\"\"\n",
    "                  select gvkey, lpermno as permno, linktype, linkprim, \n",
    "                  linkdt, linkenddt\n",
    "                  from crsp.ccmxpf_linktable\n",
    "                  where substr(linktype,1,1)='L'\n",
    "                  and linkprim in ('P', 'C')\n",
    "                  \"\"\")\n",
    "#CCMXPF_LINKTABLE\t\tCRSP/COMPUSTAT Merged - Link History w/ Used Flag\n",
    "#lpermno \tNum\t8\tHistorical CRSP PERMNO Link to COMPUSTAT Record\n",
    "# linktype \tChar\t2\tLink Type Code,\n",
    "# Link Type Code is a 2-character code providing additional detail on the usage of the link data available.\n",
    "# linkprim \tChar\t1\tPrimary Link Marker\n",
    "# linkdt \tNum\t8\tFirst Effective Date of Link\n",
    "# linkenddt \tNum\t8\tLast Effective Date of Link\n",
    "\n",
    "ccm['linkdt']=pd.to_datetime(ccm['linkdt'])\n",
    "ccm['linkenddt']=pd.to_datetime(ccm['linkenddt'])\n",
    "# if linkenddt is missing then set to today date\n",
    "ccm['linkenddt']=ccm['linkenddt'].fillna(pd.to_datetime('today'))\n",
    "#attention: pd.to.datetime does not convert today(M8[ns]) into format '%Y\\%m\\%d', need to go with ccm[].dt.date\n",
    "# if using the code below there will be warning on server\n",
    "ccm['linkenddt']=ccm['linkenddt'].dt.date\n",
    "\n",
    "ccm1=pd.merge(comp,ccm,how='left',on=['gvkey'])\n",
    "ccm1['yearend']=ccm1['datadate']+YearEnd(0)\n",
    "ccm1['jdate']=ccm1['yearend']+MonthEnd(6)\n",
    "\n",
    "# set link date bounds\n",
    "ccm2=ccm1[(ccm1['jdate']>=ccm1['linkdt'])&(ccm1['jdate']<=ccm1['linkenddt'])]\n",
    "# Subject to further adjustment in the future \n",
    "ccm2=ccm2.drop(columns=['datadate_a','linktype','linkdt','linkenddt'])\n",
    "# ccm2=ccm2[['gvkey','permno','datadate','yearend','jdate','be','op','inv','count']]\n",
    "\n",
    "# # link comp and crsp\n",
    "# Note: Different from SAS code, I left merge CCM2 to CRSP_JUN\n",
    "ccm_jun=pd.merge(crsp_jun, ccm2, how='inner', on=['permno', 'jdate'])\n",
    "# ccm_data is the SAS parallel\n",
    "ccm_data=pd.merge(ccm2,crsp_jun, how='left', on=['permno', 'jdate'])\n",
    "#filtering out prc==nan and dec_me==0\n",
    "ccm_jun=ccm_jun[ccm_jun.dec_me!=0]\n",
    "ccm_jun['beme']=ccm_jun['be']*1000/ccm_jun['dec_me']\n",
    "\n",
    "# drop duplicates\n",
    "ccm_jun=ccm_jun.sort_values(by=['permno','date']).drop_duplicates()\n",
    "ccm_jun=ccm_jun.sort_values(by=['gvkey','date']).drop_duplicates()\n",
    "\n",
    "# Note: Different from SAS, Python count start from zero, will see if I need to add 1 to better serve the need\n",
    "ccm_jun['count']=ccm_jun.groupby(['gvkey']).cumcount()\n",
    "\n",
    "# Parallel to the cleaning step for 'dr'\n",
    "ccm_jun['dr']=np.where(ccm_jun.drc.notna() & ccm_jun.drlt.notna(),ccm_jun.drc+ccm_jun.drlt,None)\n",
    "ccm_jun['dr']=np.where(ccm_jun.drc.notna() & ccm_jun.drlt.isna(),ccm_jun.drc,ccm_jun['dr'])\n",
    "ccm_jun['dr']=np.where(ccm_jun.drc.isna() & ccm_jun.drlt.notna(),ccm_jun.drlt,ccm_jun['dr'])\n",
    "# Parallel to the cleaning step for 'dc'\n",
    "ccm_jun['dc']=np.where(ccm_jun.dcvt.isna() & ccm_jun.dcpstk.notna() & ccm_jun.pstk.notna() & (ccm_jun.dcpstk>ccm_jun.pstk),\\\n",
    "                       ccm_jun.dcpstk-ccm_jun.pstk,None)\n",
    "ccm_jun['dc']=np.where(ccm_jun.dcvt.isna() & ccm_jun.dcpstk.notna() & ccm_jun.pstk.isna(),\\\n",
    "                       ccm_jun.dcpstk,ccm_jun['dr'])\n",
    "ccm_jun['dc']=np.where(ccm_jun.dc.isna(), ccm_jun.dcvt, ccm_jun['dr'])\n",
    "ccm_jun['xint']=ccm_jun['xint'].fillna(0)\n",
    "ccm_jun['xsga']=ccm_jun['xsga'].fillna(0)\n",
    "\n",
    "ccm_jun=ccm_jun.sort_values(by=['permno','date']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# more clean-up and create first pass of variables           #\n",
    "#######################\n",
    "#create simple-just annual Compustat variables\n",
    "\n",
    "ccm_jun['ep']=ccm_jun.ib/ccm_jun.mve_f\n",
    "ccm_jun['cashpr']=(ccm_jun.mve_f+ccm_jun.dltt-ccm_jun['at'])/ccm_jun.che\n",
    "ccm_jun['dy']=ccm_jun.dvt/ccm_jun.mve_f\n",
    "ccm_jun['lev']=ccm_jun['lt']/ccm_jun.mve_f\n",
    "ccm_jun['sp']=ccm_jun.sale/ccm_jun.mve_f\n",
    "ccm_jun['roic']=(ccm_jun.ebit-ccm_jun.nopi)/(ccm_jun.ceq+ccm_jun['lt']-ccm_jun.che)\n",
    "ccm_jun['rd_sale']=ccm_jun.xrd/ccm_jun.sale\n",
    "ccm_jun['sp']=ccm_jun.sale/ccm_jun.mve_f\n",
    "\n",
    "#Deleting duplicated columns\n",
    "# ccm_jun = ccm_jun.loc[:,~ccm_jun.columns.duplicated()]\n",
    "\n",
    "# treatment for lagged terms\n",
    "ccm_jun['lagat']=ccm_jun.groupby(['permno'])['at'].shift(1)\n",
    "ccm_jun['lagcsho']=ccm_jun.groupby(['permno'])['csho'].shift(1)\n",
    "ccm_jun['laglt']=ccm_jun.groupby(['permno'])['lt'].shift(1)\n",
    "ccm_jun['lagact']=ccm_jun.groupby(['permno'])['act'].shift(1)\n",
    "ccm_jun['lagche']=ccm_jun.groupby(['permno'])['che'].shift(1)\n",
    "ccm_jun['lagdlc']=ccm_jun.groupby(['permno'])['dlc'].shift(1)\n",
    "ccm_jun['lagtxp']=ccm_jun.groupby(['permno'])['txp'].shift(1)\n",
    "ccm_jun['laglct']=ccm_jun.groupby(['permno'])['lct'].shift(1)\n",
    "ccm_jun['laginvt']=ccm_jun.groupby(['permno'])['invt'].shift(1)\n",
    "ccm_jun['lagemp']=ccm_jun.groupby(['permno'])['emp'].shift(1)\n",
    "ccm_jun['lagsale']=ccm_jun.groupby(['permno'])['sale'].shift(1)\n",
    "ccm_jun['lagib']=ccm_jun.groupby(['permno'])['ib'].shift(1)\n",
    "ccm_jun['lag2at']=ccm_jun.groupby(['permno'])['at'].shift(2)\n",
    "ccm_jun['lagrect']=ccm_jun.groupby(['permno'])['rect'].shift(1)\n",
    "ccm_jun['lagcogs']=ccm_jun.groupby(['permno'])['cogs'].shift(1)\n",
    "ccm_jun['lagxsga']=ccm_jun.groupby(['permno'])['xsga'].shift(1)\n",
    "ccm_jun['lagppent']=ccm_jun.groupby(['permno'])['ppent'].shift(1)\n",
    "ccm_jun['lagdp']=ccm_jun.groupby(['permno'])['dp'].shift(1)\n",
    "ccm_jun['lagxad']=ccm_jun.groupby(['permno'])['xad'].shift(1)\n",
    "ccm_jun['lagppegt']=ccm_jun.groupby(['permno'])['ppegt'].shift(1)\n",
    "ccm_jun['lagceq']=ccm_jun.groupby(['permno'])['ceq'].shift(1)\n",
    "ccm_jun['lagcapx']=ccm_jun.groupby(['permno'])['capx'].shift(1)\n",
    "ccm_jun['lag2capx']=ccm_jun.groupby(['permno'])['capx'].shift(2)\n",
    "ccm_jun['laggdwl']=ccm_jun.groupby(['permno'])['gdwl'].shift(1)\n",
    "\n",
    "ccm_jun['agr']=np.where(ccm_jun['at'].isna() | ccm_jun.lagat.isna(), np.NaN, (ccm_jun.lagat-ccm_jun['at'])/ccm_jun.lagat)\n",
    "ccm_jun['gma']=ccm_jun.revt-ccm_jun.cogs/ccm_jun.lagat\n",
    "ccm_jun['chcsho']=ccm_jun.csho/ccm_jun.lagcsho -1\n",
    "ccm_jun['lgr']=ccm_jun['lt']/ccm_jun.laglt -1\n",
    "ccm_jun['acc']=(ccm_jun.ib-ccm_jun.oancf)/(ccm_jun['at']+ccm_jun.lagat) -1\n",
    "\n",
    "ccm_jun['pctacc']=np.where(ccm_jun['ib']==0,(ccm_jun['ib']-ccm_jun['oancf'])/0.01, np.NaN)\n",
    "ccm_jun['pctacc']=np.where(ccm_jun['oancf'].isna(),(ccm_jun['act']-ccm_jun['lagact']-(ccm_jun['che']-ccm_jun['lagche']))\\\n",
    "                           -(ccm_jun['lct']-ccm_jun['laglct']-(ccm_jun['dlc']-ccm_jun['lagdlc'])\\\n",
    "                            -(ccm_jun['txp']-ccm_jun['lagtxp'])-ccm_jun['dp'])/ccm_jun['ib'].abs(), ccm_jun['pctacc'])\n",
    "ccm_jun['pctacc']=np.where(ccm_jun['oancf'].isna() & ccm_jun['ib']==0, (ccm_jun['act']-ccm_jun['lagact']-(ccm_jun['che']-ccm_jun['lagche']))\\\n",
    "                           -(ccm_jun['lct']-ccm_jun['laglct']-(ccm_jun['dlc']-ccm_jun['lagdlc'])\\\n",
    "                            -(ccm_jun['txp']-ccm_jun['lagtxp'])-ccm_jun['dp'])/0.01, ccm_jun['pctacc'])\n",
    "\n",
    "ccm_jun['cfp']= (ccm_jun['ib']-(ccm_jun['act']-ccm_jun['lagact']-(ccm_jun['che']-ccm_jun['lagche'])))\\\n",
    "                -(ccm_jun['lct']-ccm_jun['laglct']-(ccm_jun['dlc']-ccm_jun['lagdlc'])\\\n",
    "                  -(ccm_jun['txp']-ccm_jun['lagtxp'])-ccm_jun['dp'])/ccm_jun['mve_f']\n",
    "ccm_jun['cfp']=np.where(ccm_jun['oancf'].notna(),ccm_jun['oancf']/ccm_jun['mve_f'], ccm_jun['cfp'])\n",
    "ccm_jun['absacc']=ccm_jun['acc'].abs()\n",
    "ccm_jun['chinv']=2*(ccm_jun['invt']-ccm_jun['laginvt'])/(ccm_jun['at']+ccm_jun['lagat'])\n",
    "ccm_jun['spii']=np.where((ccm_jun['spi']!=0)&ccm_jun['spi'].notna(), 1, 0)\n",
    "\n",
    "ccm_jun['spi']=2*ccm_jun['spi']/(ccm_jun['at']+ccm_jun['lagat'])\n",
    "ccm_jun['cf']=2*ccm_jun['oancf']/(ccm_jun['at']+ccm_jun['lagat'])\n",
    "\n",
    "ccm_jun['cf']=np.where(ccm_jun['oancf'].isna(), (ccm_jun['ib']-(ccm_jun['act']-ccm_jun['lagact']-(ccm_jun['che']-ccm_jun['lagche'])))\\\n",
    "                -(ccm_jun['lct']-ccm_jun['laglct']-(ccm_jun['dlc']-ccm_jun['lagdlc'])\\\n",
    "                  -(ccm_jun['txp']-ccm_jun['lagtxp'])-ccm_jun['dp'])/((ccm_jun['at']+ccm_jun['lagat'])/2),ccm_jun['cf'])  \n",
    "ccm_jun['hire']=ccm_jun['emp']-ccm_jun['lagemp']/ccm_jun['lagemp']\n",
    "ccm_jun['hire']=np.where(ccm_jun['emp'].isna() | ccm_jun['lagemp'].isna(), 0, ccm_jun['hire'])\n",
    "\n",
    "ccm_jun['sgr']=ccm_jun['sale']/ccm_jun['lagsale'] -1\n",
    "ccm_jun['chpm']=ccm_jun['ib']/ccm_jun['sale']-ccm_jun['lagib']/ccm_jun['lagsale']\n",
    "ccm_jun['chato']=(ccm_jun['sale']/((ccm_jun['at']+ccm_jun['lagat'])/2)) - (ccm_jun['lagsale']/((ccm_jun['lagat'])+ccm_jun['lag2at'])/2)\n",
    "ccm_jun['pchsale_pchinvt']=((ccm_jun['sale']-(ccm_jun['lagsale']))/(ccm_jun['lagsale']))-((ccm_jun['invt']-(ccm_jun['laginvt']))/(ccm_jun['laginvt']))\n",
    "ccm_jun['pchsale_pchrect']=((ccm_jun['sale']-(ccm_jun['lagsale']))/(ccm_jun['lagsale']))-((ccm_jun['rect']-(ccm_jun['lagrect']))/(ccm_jun['lagrect']))\n",
    "ccm_jun['pchgm_pchsale']=(((ccm_jun['sale']-ccm_jun['cogs'])-((ccm_jun['lagsale'])-(ccm_jun['lagcogs'])))/((ccm_jun['lagsale'])-(ccm_jun['lagcogs'])))-((ccm_jun['sale']-(ccm_jun['lagsale']))/(ccm_jun['lagsale']))\n",
    "ccm_jun['pchsale_pchxsga']=((ccm_jun['sale']-(ccm_jun['lagsale']))/(ccm_jun['lagsale']) )-((ccm_jun['xsga']\\\n",
    "        -(ccm_jun['lagxsga'])) /(ccm_jun['lagxsga']) )\n",
    "ccm_jun['depr']=ccm_jun['dp']/ccm_jun['ppent']\n",
    "ccm_jun['pchdepr']=((ccm_jun['dp']/ccm_jun['ppent'])-((ccm_jun['lagdp'])/(ccm_jun['lagppent'])))/((ccm_jun['lagdp'])/(ccm_jun['lagppent']))\n",
    "ccm_jun['chadv']=np.log(1+ccm_jun['xad'])-np.log((1+(ccm_jun['lagxad'])))\n",
    "ccm_jun['invest']=((ccm_jun['ppegt']-(ccm_jun['lagppegt'])) +  (ccm_jun['invt']-(ccm_jun['laginvt'])) ) / (ccm_jun['lagat'])\n",
    "ccm_jun['invest']=np.where(ccm_jun['ppegt'].isna(), ((ccm_jun['ppent']-(ccm_jun['lagppent'])) +  (ccm_jun['invt']-(ccm_jun['laginvt'])) ) / (ccm_jun['lagat']), ccm_jun['invest'])\n",
    "ccm_jun['egr']=((ccm_jun['ceq']-(ccm_jun['lagceq']))/(ccm_jun['lagceq']) )\n",
    "\n",
    "# Note here instead of using count>=2, I use 1 to stay in line iwth python cumcount\n",
    "# Also starting from here I'll keep the SAS in the notes for comparison and debug\n",
    "    # \tif missing(capx) and count>=2 then\n",
    "    # \t\tcapx=ppent-lag(ppent);\n",
    "    # \tpchcapx=(capx-lag(capx))/lag(capx);\n",
    "    # \tgrcapx=(capx-lag2(capx))/lag2(capx);\n",
    "    # \tgrGW=(gdwl-lag(gdwl))/lag(gdwl);\n",
    "ccm_jun['capx']=np.where(ccm_jun['capx'].isna() & ccm_jun['count']>=1,ccm_jun['ppent']-(ccm_jun['lagppent']), ccm_jun['capx'])\n",
    "ccm_jun['pchcapx']=ccm_jun['capx']-ccm_jun['lagcapx']/ccm_jun['lagcapx']\n",
    "ccm_jun['grcapx']=ccm_jun['capx']-ccm_jun['lag2capx']/ccm_jun['lag2capx']\n",
    "ccm_jun['grGW']=ccm_jun['gdwl']-ccm_jun['laggdwl']/ccm_jun['laggdwl']\n",
    "    # \tif missing(gdwl) or gdwl=0 then\n",
    "    # \t\tgrGW=0;\n",
    "    # \tif gdwl ne 0 and not missing(gdwl) and missing(grGW) then\n",
    "    # \t\tgrGW=1;\n",
    "ccm_jun['grGW']=np.where(ccm_jun['gdwl'].isna() | ccm_jun['gdwl']==0, 0, ccm_jun['grGW'])  \n",
    "ccm_jun['grGW']=np.where(ccm_jun['gdwl'].notna() & ccm_jun['gdwl']!=0 & ccm_jun['grGW'].isna(), 1, ccm_jun['grGW']) \n",
    "    # \tif (not missing(gdwlia) and gdwlia ne 0) or (not missing(gdwlip) and gdwlip ne \n",
    "    # \t\t0) or (not missing(gwo) and gwo ne 0) then\n",
    "    # \t\t\twoGW=1;\n",
    "ccm_jun['woGW']=np.where((ccm_jun['gdwlia'].notna()&ccm_jun['gdwlia']!=0)|(ccm_jun['gdwlip'].notna()&(ccm_jun['gdwlip']!=0))|\\\n",
    "                                                                          (ccm_jun['gwo'].notna()&ccm_jun['gwo']!=0) , 1, 0)\n",
    "    #\ttang=(che+rect*0.715+invt*0.547+ppent*0.535)/at;\n",
    "ccm_jun['tang']=(ccm_jun['che']+ccm_jun['rect']*0.715+ccm_jun['invt']*0.547+ccm_jun['ppent']*0.535)/ccm_jun['at']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
